{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e50e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models,transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import TensorDataset, DataLoader,random_split\n",
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.autograd import Function\n",
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torchvision.models as models\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import collections\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from sklearn.model_selection import KFold\n",
    "# from torchsummary import summary\n",
    "import glob\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import collections\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "import random\n",
    "\n",
    "SAVING_FRAMES_PER_SECOND = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "854d81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_FOLDER = \"/media/data_cifs/nih/files_to_send/\"\n",
    "ACTION_FOLDER = \"/media/data_cifs/nih/inference/results_csv/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdfe5116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohort_search(cohort, search_root, ret=False):\n",
    "    cohort = str(cohort).upper()\n",
    "    all_folders = [folder for folder in os.listdir(search_root) if folder.startswith(\"FC-\"+cohort)]\n",
    "    all_folders.sort()\n",
    "    all_folder_list = \"\\n\".join(all_folders)\n",
    "    if ret:\n",
    "        return all_folders\n",
    "    else:\n",
    "        print(all_folder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb536421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mouse_videos(mouse_id, cohort, ret=False):\n",
    "    \n",
    "    search_for = \"v\"\n",
    "    \n",
    "    if search_for == \"videos\":\n",
    "        print(\"Looking for videos..\")\n",
    "        file_extension = \".mp4\" \n",
    "        ROOT_FOLDER = VIDEO_FOLDER\n",
    "    else:\n",
    "        print(\"Looking for actions...\")\n",
    "        file_extension = \".csv\"\n",
    "        ROOT_FOLDER = ACTION_FOLDER\n",
    "    \n",
    "    mouse_id = str(mouse_id)\n",
    "    cohort_folders = cohort_search(cohort, ROOT_FOLDER, ret=True)\n",
    "    \n",
    "    preexposure_folders = [folder for folder in cohort_folders if \"exp\" in folder]\n",
    "    postcond_folders = [folder for folder in cohort_folders if \"cond\" in folder]\n",
    "    postext_folders = [folder for folder in cohort_folders if \"xt\" in folder]\n",
    "    postret_folders = [folder for folder in cohort_folders if \"tre\" in folder]\n",
    "    \n",
    "    preexposure_videos = []\n",
    "    postcond_videos = []\n",
    "    postext_videos = []\n",
    "    postret_videos = []\n",
    "    \n",
    "    for folder in preexposure_folders:\n",
    "        preexposure_videos += [video+'/'+folder for video in os.listdir(ROOT_FOLDER+folder) if (mouse_id in video and video.endswith(file_extension) and os.stat(ROOT_FOLDER+folder+'/'+video).st_size)]\n",
    "    preexposure_videos.sort()\n",
    "    \n",
    "    for folder in postcond_folders:\n",
    "        postcond_videos += [video+'/'+folder for video in os.listdir(ROOT_FOLDER+folder) if (mouse_id in video and video.endswith(file_extension) and os.stat(ROOT_FOLDER+folder+'/'+video).st_size)]\n",
    "    postcond_videos.sort()\n",
    "    \n",
    "    for folder in postext_folders:\n",
    "        postext_videos += [video+'/'+folder for video in os.listdir(ROOT_FOLDER+folder) if (mouse_id in video and video.endswith(file_extension) and os.stat(ROOT_FOLDER+folder+'/'+video).st_size)]\n",
    "    postext_videos.sort()\n",
    "    \n",
    "    for folder in postret_folders:\n",
    "        postret_videos += [video+'/'+folder for video in os.listdir(ROOT_FOLDER+folder) if (mouse_id in video and video.endswith(file_extension) and os.stat(ROOT_FOLDER+folder+'/'+video).st_size)]\n",
    "    postret_videos.sort()\n",
    "    \n",
    "    if ret:\n",
    "        return preexposure_videos, postcond_videos\n",
    "    else:\n",
    "        print(\"\\nPREEXPOSURE:\")\n",
    "        print(\"\\n\".join(preexposure_videos))\n",
    "        print(\"\\nPOSTCONDITIONING:\")\n",
    "        print(\"\\n\".join(postcond_videos))\n",
    "        print(\"\\nPOSTEXTINCTION:\")\n",
    "        print(\"\\n\".join(postext_videos))\n",
    "        print(\"\\nPOSTRETRIEVAL:\")\n",
    "        print(\"\\n\".join(postret_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dff530a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BEH_LABELS = ['drink', 'eat', 'groom', 'hang', 'sniff', 'rear', 'rest', 'walk', 'nibble']\n",
    "action_colours = ['tab:blue', 'tab:orange', 'limegreen', 'deepskyblue', 'tab:pink', 'tab:purple', 'tab:brown', 'red', 'black']\n",
    "len(action_colours) == len(BEH_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166cea79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# READING THE CSV: postcond2_actions[0].iloc[2][1]\n",
    "# Loading actions\n",
    "# 17202338:\n",
    "preexposure_actions_17202338_a = []\n",
    "postcond_actions_17202338_a = []\n",
    "postext_actions_17202338_a = []\n",
    "postret_actions_17202338_a = []\n",
    "\n",
    "preexposure_video_list_17202338_a = [\n",
    "\"video_2018Y_08M_10D_23h_56m_27s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_00h_56m_27s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_01h_56m_28s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_02h_56m_28s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_03h_56m_28s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_04h_56m_28s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_05h_56m_28s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_06h_56m_29s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_07h_56m_29s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_09h_56m_29s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_10h_56m_29s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_11h_56m_30s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_12h_56m_30s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_13h_56m_30s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_14h_56m_30s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_15h_56m_31s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_16h_56m_31s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_17h_56m_31s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_18h_56m_31s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_19h_56m_31s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_20h_56m_32s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_21h_56m_32s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_22h_56m_32s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_11D_23h_56m_32s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_12D_00h_56m_32s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_12D_01h_56m_33s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_12D_02h_56m_33s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_12D_03h_56m_34s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_12D_04h_56m_34s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_12D_05h_56m_34s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_12D_06h_56m_34s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "\"video_2018Y_08M_12D_07h_56m_35s_cam_17202338-0000.csv/FC-A_08-09-18_preexposure\",\n",
    "]\n",
    "\n",
    "\n",
    "for action_list in preexposure_video_list_17202338_a:\n",
    "    folder_name = action_list.split('/')[-1]\n",
    "    action_file = action_list.split('/')[0]\n",
    "    csv_name = ACTION_FOLDER+folder_name+\"/\"+action_file\n",
    "    actions = pd.read_csv(csv_name)\n",
    "    print(\"Reading CSV:\", csv_name)\n",
    "    preexposure_actions_17202338_a.append(actions)\n",
    "\n",
    "print(\"Preexposure Files:\", len(preexposure_actions_17202338_a))\n",
    "\n",
    "postcond_video_list_17202338_a = [\n",
    "\"video_2018Y_08M_13D_23h_21m_05s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_00h_21m_05s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_01h_21m_05s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_02h_21m_05s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_03h_21m_05s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_04h_21m_05s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_05h_21m_05s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_06h_21m_05s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_07h_21m_06s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_09h_28m_54s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_10h_28m_55s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_11h_28m_55s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_12h_28m_56s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_13h_28m_56s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_14h_28m_56s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_15h_28m_57s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_16h_28m_57s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_17h_28m_58s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_18h_28m_58s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_19h_28m_58s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_20h_28m_58s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_21h_28m_58s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_22h_28m_58s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_14D_23h_28m_59s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_15D_00h_28m_59s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_15D_01h_28m_59s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_15D_02h_28m_59s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_15D_03h_28m_59s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_15D_04h_28m_59s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_15D_05h_28m_59s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_15D_06h_29m_00s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "\"video_2018Y_08M_15D_07h_29m_00s_cam_17202338-0000.csv/FC-A_08-10-18_postcond\",\n",
    "]\n",
    "\n",
    "for action_list in postcond_video_list_17202338_a:\n",
    "    folder_name = action_list.split('/')[-1]\n",
    "    action_file = action_list.split('/')[0]\n",
    "    csv_name = ACTION_FOLDER+folder_name+\"/\"+action_file\n",
    "    actions = pd.read_csv(csv_name)\n",
    "    print(\"Reading CSV:\", csv_name)\n",
    "    postcond_actions_17202338_a.append(actions)\n",
    "print(\"Postcond Files:\", len(postcond_actions_17202338_a))\n",
    "    \n",
    "postext_video_list_17202338_a = [\n",
    "\"video_2018Y_08M_15D_23h_58m_47s_cam_17202338-0000.csv/FC-A_08-15-18_postext\",\n",
    "\"video_2018Y_08M_16D_00h_58m_47s_cam_17202338-0000.csv/FC-A_08-15-18_postext\",\n",
    "\"video_2018Y_08M_16D_01h_58m_47s_cam_17202338-0000.csv/FC-A_08-15-18_postext\",\n",
    "\"video_2018Y_08M_16D_02h_58m_48s_cam_17202338-0000.csv/FC-A_08-15-18_postext\",\n",
    "\"video_2018Y_08M_16D_03h_58m_49s_cam_17202338-0000.csv/FC-A_08-15-18_postext\",\n",
    "]\n",
    "\n",
    "for action_list in postext_video_list_17202338_a:\n",
    "    folder_name = action_list.split('/')[-1]\n",
    "    action_file = action_list.split('/')[0]\n",
    "    csv_name = ACTION_FOLDER+folder_name+\"/\"+action_file\n",
    "    actions = pd.read_csv(csv_name)\n",
    "    print(\"Reading CSV:\", csv_name)\n",
    "    postext_actions_17202338_a.append(actions)\n",
    "\n",
    "print(\"Postext Files:\", len(postext_actions_17202338_a))\n",
    "\n",
    "postret_video_list_17202338_a = [\n",
    "\"video_2018Y_08M_20D_23h_54m_37s_cam_17202338-0000.csv/FC-A_08-20-18_postret\",\n",
    "\"video_2018Y_08M_21D_00h_54m_37s_cam_17202338-0000.csv/FC-A_08-20-18_postret\",\n",
    "\"video_2018Y_08M_21D_01h_54m_37s_cam_17202338-0000.csv/FC-A_08-20-18_postret\",\n",
    "\"video_2018Y_08M_21D_02h_54m_37s_cam_17202338-0000.csv/FC-A_08-20-18_postret\",\n",
    "\"video_2018Y_08M_21D_03h_54m_37s_cam_17202338-0000.csv/FC-A_08-20-18_postret\",\n",
    "]\n",
    "\n",
    "for action_list in postret_video_list_17202338_a:\n",
    "    folder_name = action_list.split('/')[-1]\n",
    "    action_file = action_list.split('/')[0]\n",
    "    csv_name = ACTION_FOLDER+folder_name+\"/\"+action_file\n",
    "    actions = pd.read_csv(csv_name)\n",
    "    print(\"Reading CSV:\", csv_name)\n",
    "    postret_actions_17202338_a.append(actions)\n",
    "\n",
    "print(\"Postret Files:\", len(postret_actions_17202338_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd972d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# READING THE CSV: postcond2_actions[0].iloc[2][1]\n",
    "# Loading actions\n",
    "# 17202338:\n",
    "preexposure_actions_17202338_b = []\n",
    "postcond_actions_17202338_b = []\n",
    "postext_actions_17202338_b = []\n",
    "postret_actions_17202338_b = []\n",
    "\n",
    "preexposure_video_list_17202338_b = [\n",
    "\"video_2018Y_09M_19D_23h_02m_56s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_00h_02m_57s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_01h_02m_58s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_02h_03m_00s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_03h_03m_01s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_04h_03m_02s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_05h_03m_03s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_06h_03m_04s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_07h_03m_05s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_08h_03m_05s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_09h_03m_06s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_10h_06m_00s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_11h_06m_03s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_12h_06m_05s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_13h_06m_06s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_14h_06m_08s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_15h_06m_09s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_16h_06m_09s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_17h_06m_10s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_18h_06m_11s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_19h_06m_12s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_20h_06m_13s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_21h_06m_13s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_22h_06m_14s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_20D_23h_06m_15s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_2\",\n",
    "\"video_2018Y_09M_21D_00h_06m_16s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_3\",\n",
    "\"video_2018Y_09M_21D_01h_06m_17s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_3\",\n",
    "\"video_2018Y_09M_21D_02h_06m_18s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_3\",\n",
    "\"video_2018Y_09M_21D_03h_06m_18s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_3\",\n",
    "\"video_2018Y_09M_21D_04h_06m_19s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_3\",\n",
    "\"video_2018Y_09M_21D_05h_06m_20s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_3\",\n",
    "\"video_2018Y_09M_21D_06h_06m_21s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_3\",\n",
    "\"video_2018Y_09M_21D_07h_06m_21s_cam_17202338-0000.csv/FC-B_1-6_Preexposure_09-17_09-21_3\",\n",
    "]\n",
    "\n",
    "\n",
    "for action_list in preexposure_video_list_17202338_b:\n",
    "    folder_name = action_list.split('/')[-1]\n",
    "    action_file = action_list.split('/')[0]\n",
    "    csv_name = ACTION_FOLDER+folder_name+\"/\"+action_file\n",
    "    actions = pd.read_csv(csv_name)\n",
    "    print(\"Reading CSV:\", csv_name)\n",
    "    preexposure_actions_17202338_b.append(actions)\n",
    "\n",
    "print(\"Preexposure Files:\", len(preexposure_actions_17202338_b))\n",
    "\n",
    "postcond_video_list_17202338_b = [\n",
    "\"video_2018Y_09M_21D_23h_39m_45s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_00h_39m_45s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_01h_39m_46s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_02h_39m_47s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_03h_39m_47s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_04h_39m_48s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_05h_39m_49s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_06h_39m_49s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_07h_39m_50s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_08h_39m_51s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_09h_39m_51s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_10h_39m_52s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_11h_39m_53s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_12h_39m_54s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_13h_39m_54s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_14h_39m_55s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_15h_39m_55s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_16h_39m_56s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_17h_39m_57s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_18h_39m_57s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_19h_39m_58s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_20h_39m_59s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_21h_39m_59s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_22h_40m_00s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_22D_23h_40m_00s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_23D_00h_40m_01s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_23D_01h_40m_02s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_23D_02h_40m_02s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_23D_03h_40m_03s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_23D_04h_40m_04s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_23D_05h_40m_04s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_23D_06h_40m_05s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "\"video_2018Y_09M_23D_07h_40m_05s_cam_17202338-0000.csv/FC-B_1-6_postcond_09-21_09-23_2\",\n",
    "]\n",
    "\n",
    "for action_list in postcond_video_list_17202338_b:\n",
    "    folder_name = action_list.split('/')[-1]\n",
    "    action_file = action_list.split('/')[0]\n",
    "    csv_name = ACTION_FOLDER+folder_name+\"/\"+action_file\n",
    "    actions = pd.read_csv(csv_name)\n",
    "    print(\"Reading CSV:\", csv_name)\n",
    "    postcond_actions_17202338_b.append(actions)\n",
    "print(\"Postcond Files:\", len(postcond_actions_17202338_b))\n",
    "    \n",
    "# postext_video_list_17202338_a = [\n",
    "# \"video_2018Y_08M_15D_23h_58m_47s_cam_17202338-0000.csv/FC-A_08-15-18_postext\",\n",
    "# \"video_2018Y_08M_16D_00h_58m_47s_cam_17202338-0000.csv/FC-A_08-15-18_postext\",\n",
    "# \"video_2018Y_08M_16D_01h_58m_47s_cam_17202338-0000.csv/FC-A_08-15-18_postext\",\n",
    "# \"video_2018Y_08M_16D_02h_58m_48s_cam_17202338-0000.csv/FC-A_08-15-18_postext\",\n",
    "# \"video_2018Y_08M_16D_03h_58m_49s_cam_17202338-0000.csv/FC-A_08-15-18_postext\",\n",
    "# ]\n",
    "\n",
    "# for action_list in postext_video_list_17202338_a:\n",
    "#     folder_name = action_list.split('/')[-1]\n",
    "#     action_file = action_list.split('/')[0]\n",
    "#     csv_name = ACTION_FOLDER+folder_name+\"/\"+action_file\n",
    "#     actions = pd.read_csv(csv_name)\n",
    "#     print(\"Reading CSV:\", csv_name)\n",
    "#     postext_actions_17202338_a.append(actions)\n",
    "\n",
    "# print(\"Postext Files:\", len(postext_actions_17202338_a))\n",
    "\n",
    "# postret_video_list_17202338_a = [\n",
    "# \"video_2018Y_08M_20D_23h_54m_37s_cam_17202338-0000.csv/FC-A_08-20-18_postret\",\n",
    "# \"video_2018Y_08M_21D_00h_54m_37s_cam_17202338-0000.csv/FC-A_08-20-18_postret\",\n",
    "# \"video_2018Y_08M_21D_01h_54m_37s_cam_17202338-0000.csv/FC-A_08-20-18_postret\",\n",
    "# \"video_2018Y_08M_21D_02h_54m_37s_cam_17202338-0000.csv/FC-A_08-20-18_postret\",\n",
    "# \"video_2018Y_08M_21D_03h_54m_37s_cam_17202338-0000.csv/FC-A_08-20-18_postret\",\n",
    "# ]\n",
    "\n",
    "# for action_list in postret_video_list_17202338_a:\n",
    "#     folder_name = action_list.split('/')[-1]\n",
    "#     action_file = action_list.split('/')[0]\n",
    "#     csv_name = ACTION_FOLDER+folder_name+\"/\"+action_file\n",
    "#     actions = pd.read_csv(csv_name)\n",
    "#     print(\"Reading CSV:\", csv_name)\n",
    "#     postret_actions_17202338_a.append(actions)\n",
    "\n",
    "# print(\"Postret Files:\", len(postret_actions_17202338_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9413888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING THE CSV: postcond2_actions[0].iloc[2][1]\n",
    "# Loading actions\n",
    "# 17202338:\n",
    "preexposure_actions_17202338_c = []\n",
    "postcond_actions_17202338_c = []\n",
    "postext_actions_17202338_c = []\n",
    "postret_actions_17202338_c = []\n",
    "\n",
    "preexposure_video_list_17202338_c = [\n",
    "\"video_2018Y_10M_13D_23h_04m_00s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_00h_04m_01s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_01h_04m_02s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_02h_04m_03s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_03h_04m_04s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_04h_04m_05s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_05h_04m_07s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_06h_04m_08s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_07h_04m_09s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_08h_04m_10s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_09h_04m_10s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_10h_04m_11s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_11h_04m_12s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_12h_04m_12s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_13h_04m_13s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_14h_04m_14s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_15h_04m_15s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_16h_04m_16s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_17h_04m_17s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_18h_04m_18s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_19h_04m_18s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_20h_04m_19s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_21h_04m_20s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_22h_04m_21s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_14D_23h_04m_22s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_15D_00h_04m_22s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_15D_01h_04m_23s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_15D_02h_04m_24s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_15D_03h_04m_25s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_15D_04h_04m_25s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_15D_05h_04m_26s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "\"video_2018Y_10M_15D_06h_04m_27s_cam_17202338-0000.csv/FC-C_1-6_Preexposure_10-11_10-15\",\n",
    "]\n",
    "\n",
    "\n",
    "for action_list in preexposure_video_list_17202338_c:\n",
    "    folder_name = action_list.split('/')[-1]\n",
    "    action_file = action_list.split('/')[0]\n",
    "    csv_name = ACTION_FOLDER+folder_name+\"/\"+action_file\n",
    "    actions = pd.read_csv(csv_name)\n",
    "    print(\"Reading CSV:\", csv_name)\n",
    "    preexposure_actions_17202338_c.append(actions)\n",
    "\n",
    "print(\"Preexposure Files:\", len(preexposure_actions_17202338_c))\n",
    "\n",
    "postcond_video_list_17202338_c = [\n",
    "\"video_2018Y_10M_15D_23h_16m_17s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_00h_16m_18s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_01h_16m_18s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_02h_16m_19s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_03h_16m_20s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_04h_16m_21s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_05h_16m_21s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_06h_16m_22s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_07h_16m_23s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_08h_16m_24s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_09h_16m_25s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_10h_35m_40s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_11h_35m_43s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_12h_35m_45s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_13h_35m_48s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_14h_35m_49s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_15h_35m_50s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_16h_35m_50s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_17h_35m_51s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_18h_35m_52s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_19h_35m_53s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_20h_35m_54s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_21h_35m_55s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_22h_35m_56s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_16D_23h_35m_56s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_17D_00h_35m_57s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_17D_01h_35m_58s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_17D_02h_35m_58s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_17D_03h_35m_59s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_17D_04h_35m_59s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_17D_05h_36m_00s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "\"video_2018Y_10M_17D_06h_36m_01s_cam_17202338-0000.csv/FC-C_1-6_postcond_10-15_10-17\",\n",
    "]\n",
    "\n",
    "for action_list in postcond_video_list_17202338_c:\n",
    "    folder_name = action_list.split('/')[-1]\n",
    "    action_file = action_list.split('/')[0]\n",
    "    csv_name = ACTION_FOLDER+folder_name+\"/\"+action_file\n",
    "    actions = pd.read_csv(csv_name)\n",
    "    print(\"Reading CSV:\", csv_name)\n",
    "    postcond_actions_17202338_c.append(actions)\n",
    "print(\"Postcond Files:\", len(postcond_actions_17202338_c))\n",
    "    \n",
    "# postext_video_list_17202338_a = [\n",
    "# \"video_2018Y_08M_15D_23h_58m_47s_cam_17202338-0000.csv/FC-A_08-15-18_postext\",\n",
    "# \"video_2018Y_08M_16D_00h_58m_47s_cam_17202338-0000.csv/FC-A_08-15-18_postext\",\n",
    "# \"video_2018Y_08M_16D_01h_58m_47s_cam_17202338-0000.csv/FC-A_08-15-18_postext\",\n",
    "# \"video_2018Y_08M_16D_02h_58m_48s_cam_17202338-0000.csv/FC-A_08-15-18_postext\",\n",
    "# \"video_2018Y_08M_16D_03h_58m_49s_cam_17202338-0000.csv/FC-A_08-15-18_postext\",\n",
    "# ]\n",
    "\n",
    "# for action_list in postext_video_list_17202338_a:\n",
    "#     folder_name = action_list.split('/')[-1]\n",
    "#     action_file = action_list.split('/')[0]\n",
    "#     csv_name = ACTION_FOLDER+folder_name+\"/\"+action_file\n",
    "#     actions = pd.read_csv(csv_name)\n",
    "#     print(\"Reading CSV:\", csv_name)\n",
    "#     postext_actions_17202338_a.append(actions)\n",
    "\n",
    "# print(\"Postext Files:\", len(postext_actions_17202338_a))\n",
    "\n",
    "# postret_video_list_17202338_a = [\n",
    "# \"video_2018Y_08M_20D_23h_54m_37s_cam_17202338-0000.csv/FC-A_08-20-18_postret\",\n",
    "# \"video_2018Y_08M_21D_00h_54m_37s_cam_17202338-0000.csv/FC-A_08-20-18_postret\",\n",
    "# \"video_2018Y_08M_21D_01h_54m_37s_cam_17202338-0000.csv/FC-A_08-20-18_postret\",\n",
    "# \"video_2018Y_08M_21D_02h_54m_37s_cam_17202338-0000.csv/FC-A_08-20-18_postret\",\n",
    "# \"video_2018Y_08M_21D_03h_54m_37s_cam_17202338-0000.csv/FC-A_08-20-18_postret\",\n",
    "# ]\n",
    "\n",
    "# for action_list in postret_video_list_17202338_a:\n",
    "#     folder_name = action_list.split('/')[-1]\n",
    "#     action_file = action_list.split('/')[0]\n",
    "#     csv_name = ACTION_FOLDER+folder_name+\"/\"+action_file\n",
    "#     actions = pd.read_csv(csv_name)\n",
    "#     print(\"Reading CSV:\", csv_name)\n",
    "#     postret_actions_17202338_a.append(actions)\n",
    "\n",
    "# print(\"Postret Files:\", len(postret_actions_17202338_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a34cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loading actions CONTROL\n",
    "# 17202338:\n",
    "preexposure_actions_17202338_k = []\n",
    "postcond_actions_17202338_k = []\n",
    "postext_actions_17202338_k = []\n",
    "postret_actions_17202338_k = []\n",
    "\n",
    "preexposure_video_list_17202338_k = [\n",
    "\"video_2019Y_06M_04D_20h_14m_53s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_04D_21h_14m_55s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_04D_22h_14m_56s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_04D_23h_15m_00s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_00h_15m_01s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_01h_15m_02s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_02h_15m_03s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_03h_15m_08s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_04h_15m_09s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_05h_15m_14s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_06h_15m_17s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_07h_15m_18s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_08h_15m_19s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_09h_15m_20s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_10h_15m_21s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_11h_15m_22s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-04-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_13h_23m_04s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_14h_23m_05s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_15h_23m_08s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_16h_23m_12s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_17h_23m_13s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_18h_23m_17s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_19h_23m_20s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_20h_23m_22s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_21h_23m_24s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_22h_23m_25s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "\"video_2019Y_06M_05D_23h_23m_26s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "\"video_2019Y_06M_06D_00h_23m_28s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "\"video_2019Y_06M_06D_01h_23m_31s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "\"video_2019Y_06M_06D_02h_23m_35s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "\"video_2019Y_06M_06D_03h_23m_38s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "\"video_2019Y_06M_06D_04h_23m_42s_cam_6394840-0000.csv/FC-D_preexposure_W1_06-05-2019_comp2\",\n",
    "]\n",
    "\n",
    "\n",
    "for action_list in preexposure_video_list_17202338_k:\n",
    "    folder_name = action_list.split('/')[-1]\n",
    "    action_file = action_list.split('/')[0]\n",
    "    csv_name = ACTION_FOLDER+folder_name+\"/\"+action_file\n",
    "    actions = pd.read_csv(csv_name)\n",
    "    print(\"Reading CSV:\", csv_name)\n",
    "    preexposure_actions_17202338_k.append(actions)\n",
    "\n",
    "print(\"Preexposure Files:\", len(preexposure_actions_17202338_k))\n",
    "\n",
    "postcond_video_list_17202338_k = [\n",
    "\"video_2019Y_06M_06D_20h_14m_02s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_06D_21h_14m_03s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_06D_22h_14m_05s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_06D_23h_14m_08s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_00h_14m_11s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_01h_14m_14s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_02h_14m_14s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_03h_14m_15s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_04h_14m_17s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_05h_14m_18s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_06h_14m_21s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_07h_14m_21s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_08h_14m_24s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_09h_14m_26s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_10h_14m_27s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_11h_14m_27s_cam_6394840-0000.csv/FC-D_postcond_W2_06-06-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_13h_23m_06s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_14h_23m_10s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_15h_23m_13s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_16h_23m_15s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_17h_23m_18s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_18h_23m_23s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_19h_23m_24s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_20h_23m_24s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_21h_23m_29s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_22h_23m_30s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "\"video_2019Y_06M_07D_23h_23m_31s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "\"video_2019Y_06M_08D_00h_23m_31s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "\"video_2019Y_06M_08D_01h_23m_33s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "\"video_2019Y_06M_08D_02h_23m_36s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "\"video_2019Y_06M_08D_03h_23m_38s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "\"video_2019Y_06M_08D_04h_23m_39s_cam_6394840-0000.csv/FC-D_postcond_W2_06-07-2019_comp2\",\n",
    "]\n",
    "\n",
    "for action_list in postcond_video_list_17202338_k:\n",
    "    folder_name = action_list.split('/')[-1]\n",
    "    action_file = action_list.split('/')[0]\n",
    "    csv_name = ACTION_FOLDER+folder_name+\"/\"+action_file\n",
    "    actions = pd.read_csv(csv_name)\n",
    "    print(\"Reading CSV:\", csv_name)\n",
    "    postcond_actions_17202338_k.append(actions)\n",
    "print(\"Postcond Files:\", len(postcond_actions_17202338_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"/cifs/data/tserre/CLPS_Serre_Lab/nih/inference/results_csv/FC-A_08-10-18_postcond/video_2018Y_08M_14D_03h_21m_05s_cam_17202338-0000.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a3d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"walk walk walk walk walk rear rear rear rear rear rear rear rear walk walk walk walk walk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a40895",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preexposure_actions_17202338_a = np.load(\"all_preexposure_actions_17202338_a.npy\")\n",
    "\n",
    "# for action_set in preexposure_actions_17202338_a:\n",
    "#     for idx in range(len(action_set)):\n",
    "#         all_preexposure_actions_17202338_a.append(action_set.iloc[idx][1])\n",
    "\n",
    "print(\"Preexposure:\", len(all_preexposure_actions_17202338_a))\n",
    "\n",
    "all_postcond_actions_17202338_a = np.load(\"all_postcond_actions_17202338_a.npy\")\n",
    "# for action_set in postcond_actions_17202338_a:\n",
    "#     for idx in range(len(action_set)):\n",
    "#         all_postcond_actions_17202338_a.append(action_set.iloc[idx][1])\n",
    "\n",
    "print(\"Postcond:\", len(all_postcond_actions_17202338_a))\n",
    "\n",
    "# all_postext_actions_17202338_a = []\n",
    "# for action_set in postext_actions_17202338_a:\n",
    "#     for idx in range(len(action_set)):\n",
    "#         all_postext_actions_17202338_a.append(action_set.iloc[idx][1])\n",
    "# print(\"Postext:\", len(all_postext_actions_17202338_a))\n",
    "\n",
    "# all_postret_actions_17202338_a = []\n",
    "# for action_set in postret_actions_17202338_a:\n",
    "#     for idx in range(len(action_set)):\n",
    "#         all_postret_actions_17202338_a.append(action_set.iloc[idx][1])\n",
    "# print(\"Postret:\", len(all_postret_actions_17202338_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0124ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preexposure_actions_17202338_b = np.load(\"all_preexposure_actions_17202338_b.npy\")\n",
    "all_postcond_actions_17202338_b = np.load(\"all_postcond_actions_17202338_b.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966fddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preexposure_actions_17202338_c = np.load(\"all_preexposure_actions_17202338_c.npy\")\n",
    "all_postcond_actions_17202338_c = np.load(\"all_postcond_actions_17202338_c.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c53d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"all_preexposure_actions_17202338_d.npy\", all_preexposure_actions_17202338_k)\n",
    "# np.save(\"all_postcond_actions_17202338_d.npy\", all_preexposure_actions_17202338_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759315eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f860e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "for idx in range(len(a)):\n",
    "    b.append(a.iloc[idx][1])\n",
    "print(\"Preexposure:\", len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb79dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30517168",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preexposure_actions_17202338_c = []\n",
    "all_postcond_actions_17202338_c = []\n",
    "\n",
    "for action_set in preexposure_actions_17202338_c:\n",
    "    for idx in range(len(action_set)):\n",
    "        all_preexposure_actions_17202338_c.append(action_set.iloc[idx][1])\n",
    "print(\"Preexposure:\", len(all_preexposure_actions_17202338_c))\n",
    "\n",
    "for act ion_set in postcond_actions_17202338_c:\n",
    "    for idx in range(len(action_set)):\n",
    "        all_postcond_actions_17202338_c.append(action_set.iloc[idx][1])\n",
    "print(\"Postcond:\", len(all_postcond_actions_17202338_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb43fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preexposure_actions_17202338_b = []\n",
    "all_postcond_actions_17202338_b = []\n",
    "\n",
    "for action_set in preexposure_actions_17202338_b:\n",
    "    for idx in range(len(action_set)):\n",
    "        all_preexposure_actions_17202338_b.append(action_set.iloc[idx][1])\n",
    "print(\"Preexposure:\", len(all_preexposure_actions_17202338_b))\n",
    "\n",
    "for action_set in postcond_actions_17202338_b:\n",
    "    for idx in range(len(action_set)):\n",
    "        all_postcond_actions_17202338_b.append(action_set.iloc[idx][1])\n",
    "print(\"Postcond:\", len(all_postcond_actions_17202338_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e28b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preexposure_actions_17202338_k = []\n",
    "all_postcond_actions_17202338_k = []\n",
    "\n",
    "for action_set in preexposure_actions_17202338_k:\n",
    "    for idx in range(len(action_set)):\n",
    "        all_preexposure_actions_17202338_k.append(action_set.iloc[idx][1])\n",
    "print(\"Preexposure:\", len(all_preexposure_actions_17202338_k))\n",
    "\n",
    "for action_set in postcond_actions_17202338_k:\n",
    "    for idx in range(len(action_set)):\n",
    "        all_postcond_actions_17202338_k.append(action_set.iloc[idx][1])\n",
    "print(\"Postcond:\", len(all_postcond_actions_17202338_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3ee866",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_counter = {\n",
    "    'under5':0,\n",
    "    '5-10':0,\n",
    "    '10-15':0,\n",
    "    '15-20':0,\n",
    "    '20-25':0,\n",
    "    '25-30':0,\n",
    "    '30-35':0,\n",
    "    '35-40':0,\n",
    "    '40-45':0,\n",
    "    '45-50':0,\n",
    "    '50-55':0,\n",
    "    '55-60':0,\n",
    "    '60-90':0,\n",
    "    '90-450':0,\n",
    "    '450-1800':0,\n",
    "    '1800-4500':0,\n",
    "    'over4500':0,}\n",
    "\n",
    "def get_repeat_vocab(repeat_number):\n",
    "    # > '0-5'\n",
    "    # > '5-15'\n",
    "    # > '15-45'\n",
    "    # > '45-90'\n",
    "    # > '90-450'\n",
    "    # > '450-1800'\n",
    "    # > '1800-4500'\n",
    "    # > 'over4500'\n",
    "    if repeat_number > 0 and repeat_number <= 5:\n",
    "        box = \"under5\"\n",
    "    elif repeat_number > 5 and repeat_number <= 10:\n",
    "        box = \"5-10\"\n",
    "    elif repeat_number > 10 and repeat_number <= 15:\n",
    "        box = \"10-15\"\n",
    "    elif repeat_number > 15 and repeat_number <= 20:\n",
    "        box = \"15-20\"\n",
    "    elif repeat_number > 20 and repeat_number <= 25:\n",
    "        box = \"20-25\"\n",
    "    elif repeat_number > 25 and repeat_number <= 30:\n",
    "        box = \"25-30\"\n",
    "    elif repeat_number > 30 and repeat_number <= 35:\n",
    "        box = \"30-35\"\n",
    "    elif repeat_number > 35 and repeat_number <= 40:\n",
    "        box = \"35-40\"\n",
    "    elif repeat_number > 40 and repeat_number <= 45:\n",
    "        box = \"40-45\"\n",
    "    elif repeat_number > 45 and repeat_number <= 50:\n",
    "        box = \"45-50\"\n",
    "    elif repeat_number > 50 and repeat_number <= 55:\n",
    "        box = \"50-55\"\n",
    "    elif repeat_number > 55 and repeat_number <= 60:\n",
    "        box = \"55-60\"\n",
    "    elif repeat_number > 60 and repeat_number <= 90:\n",
    "        box = \"60-90\"\n",
    "    elif repeat_number > 90 and repeat_number <= 450:\n",
    "        box = \"90-450\"\n",
    "    elif repeat_number > 450 and repeat_number <= 1800:\n",
    "        box = \"450-1800\"\n",
    "    elif repeat_number > 1800 and repeat_number <= 4500:\n",
    "        box = \"1800-4500\"\n",
    "    elif repeat_number > 4500:\n",
    "        box = \"over4500\"\n",
    "    else:\n",
    "        raise ValueError('A very specific bad thing happened.')\n",
    "    time_counter[box] += 1\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a02fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_actions(action_list):time_counter = {\n",
    "    'under5':0,\n",
    "    '5-10':0,\n",
    "    '10-15':0,\n",
    "    '15-20':0,\n",
    "    '20-25':0,\n",
    "    '25-30':0,\n",
    "    '30-35':0,\n",
    "    '35-40':0,\n",
    "    '40-45':0,\n",
    "    '45-50':0,\n",
    "    '50-55':0,\n",
    "    '55-60':0,\n",
    "    '60-90':0,\n",
    "    '90-450':0,\n",
    "    '450-1800':0,\n",
    "    '1800-4500':0,\n",
    "    'over4500':0,}\n",
    "\n",
    "def get_repeat_vocab(repeat_number):\n",
    "    # > '0-5'\n",
    "    # > '5-15'\n",
    "    # > '15-45'\n",
    "    # > '45-90'\n",
    "    # > '90-450'\n",
    "    # > '450-1800'\n",
    "    # > '1800-4500'\n",
    "    # > 'over4500'\n",
    "    if repeat_number > 0 and repeat_number <= 5:\n",
    "        box = \"under5\"\n",
    "    elif repeat_number > 5 and repeat_number <= 10:\n",
    "        box = \"5-10\"\n",
    "    elif repeat_number > 10 and repeat_number <= 15:\n",
    "        box = \"10-15\"\n",
    "    elif repeat_number > 15 and repeat_number <= 20:\n",
    "        box = \"15-20\"\n",
    "    elif repeat_number > 20 and repeat_number <= 25:\n",
    "        box = \"20-25\"\n",
    "    elif repeat_number > 25 and repeat_number <= 30:\n",
    "        box = \"25-30\"\n",
    "    elif repeat_number > 30 and repeat_number <= 35:\n",
    "        box = \"30-35\"\n",
    "    elif repeat_number > 35 and repeat_number <= 40:\n",
    "        box = \"35-40\"\n",
    "    elif repeat_number > 40 and repeat_number <= 45:\n",
    "        box = \"40-45\"\n",
    "    elif repeat_number > 45 and repeat_number <= 50:\n",
    "        box = \"45-50\"\n",
    "    elif repeat_number > 50 and repeat_number <= 55:\n",
    "        box = \"50-55\"\n",
    "    elif repeat_number > 55 and repeat_number <= 60:\n",
    "        box = \"55-60\"\n",
    "    elif repeat_number > 60 and repeat_number <= 90:\n",
    "        box = \"60-90\"\n",
    "    elif repeat_number > 90 and repeat_number <= 450:\n",
    "        box = \"90-450\"\n",
    "    elif repeat_number > 450 and repeat_number <= 1800:\n",
    "        box = \"450-1800\"\n",
    "    elif repeat_number > 1800 and repeat_number <= 4500:\n",
    "        box = \"1800-4500\"\n",
    "    elif repeat_number > 4500:\n",
    "        box = \"over4500\"\n",
    "    else:\n",
    "        raise ValueError('A very specific bad thing happened.')\n",
    "    time_counter[box] += 1\n",
    "    return box\n",
    "    WINDOW_SIZE = 3 # Each side\n",
    "    \n",
    "    index = WINDOW_SIZE\n",
    "    action_length = len(action_list)\n",
    "    \n",
    "    while index < (action_length - WINDOW_SIZE - 1):\n",
    "        current_action = action_list[index]\n",
    "        window = action_list[index - WINDOW_SIZE : index + WINDOW_SIZE + 1]\n",
    "        window_elements = collections.Counter(window)\n",
    "        most_common_action = window_elements.most_common(1)[0][0]\n",
    "        if action_list[index] != most_common_action:\n",
    "            action_list[index] = most_common_action\n",
    "        index += 1\n",
    "    return action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c6161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_language_from_labels(action_list, class_label):\n",
    "    SENTENCE_LENGTH = 900 # in terms of actions\n",
    "    \n",
    "    start_index = 0\n",
    "    action_length = len(action_list)\n",
    "    \n",
    "    language = []\n",
    "    label = []\n",
    "    sentence = \"\"\n",
    "    \n",
    "    current_sentence_length = 0\n",
    "    while start_index < action_length:\n",
    "        \n",
    "        current_action = action_list[start_index]\n",
    "        current_action_label = BEH_LABELS[current_action]\n",
    "        \n",
    "        next_action_idx = start_index + 1\n",
    "        \n",
    "        while next_action_idx < action_length and current_action == action_list[next_action_idx]:\n",
    "            next_action_idx  += 1\n",
    "        repeats = next_action_idx - start_index\n",
    "        \n",
    "        # Filtering out single frame noise\n",
    "#         if repeats == 1 and current_action != action_list[next_action_idx]:\n",
    "#             start_index = next_action_idx\n",
    "#             print(\"Single action:\", action_list[next_action_idx-2], current_action, action_list[next_action_idx])\n",
    "#             continue\n",
    "        \n",
    "        if current_sentence_length == 0:\n",
    "            sentence = \"\"\n",
    "            \n",
    "        current_sentence_length += repeats\n",
    "        start_index = next_action_idx\n",
    "        \n",
    "        sentence += str(current_action_label)+\" \"+get_repeat_vocab(repeats)+\" \"\n",
    "        \n",
    "        if current_sentence_length >= SENTENCE_LENGTH:\n",
    "            language.append(sentence)\n",
    "            label.append(class_label)\n",
    "            current_sentence_length = 0\n",
    "            \n",
    "    if sentence != \"\":\n",
    "        language.append(sentence)\n",
    "        label.append(class_label)\n",
    "    return language, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df682d91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Language Length:\", len(generate_language_from_labels(all_preexposure_actions_17202338_a, 0)))\n",
    "# print(\"Original Action Length:\", len(all_preexposure_actions_17202338_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78932bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preexposure_actions_17202338_a = np.load(\"all_preexposure_actions_17202338_a.npy\")\n",
    "all_postcond_actions_17202338_a = np.load(\"all_postcond_actions_17202338_a.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a63f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_preexposure = cleaning_actions(all_preexposure_actions_17202338_a)\n",
    "print(\"Preexposure done.\")\n",
    "cleaned_postcond = cleaning_actions(all_postcond_actions_17202338_a)\n",
    "print(\"Postcond done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a55ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_preexposure_b = cleaning_actions(all_preexposure_actions_17202338_b)\n",
    "print(\"Preexposure done.\")\n",
    "cleaned_postcond_b = cleaning_actions(all_postcond_actions_17202338_b)\n",
    "print(\"Postcond done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422db9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_preexposure_c = cleaning_actions(all_preexposure_actions_17202338_c)\n",
    "print(\"Preexposure done.\")\n",
    "cleaned_postcond_c = cleaning_actions(all_postcond_actions_17202338_c)\n",
    "print(\"Postcond done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b78453",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_preexposure_d = cleaning_actions(all_preexposure_actions_17202338_d)\n",
    "print(\"Preexposure done.\")\n",
    "cleaned_postcond_d = cleaning_actions(all_postcond_actions_17202338_d)\n",
    "print(\"Postcond done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dffdebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_b = []\n",
    "labels_b = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f7a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_c = []\n",
    "labels_c = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2811484",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_k = []\n",
    "labels_k = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe1c762",
   "metadata": {},
   "outputs": [],
   "source": [
    "preexposure = generate_language_from_labels(cleaned_preexposure, 0)\n",
    "preexp_time_counter = time_counter\n",
    "raw_text += preexposure[0]\n",
    "labels += preexposure[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f030ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcond = generate_language_from_labels(cleaned_postcond, 1)\n",
    "postcond_time_counter = time_counter\n",
    "raw_text += postcond[0]\n",
    "labels += postcond[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c1bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC-B\n",
    "preexposure_b = generate_language_from_labels(cleaned_preexposure_b, 0)\n",
    "preexp_time_counter_b = time_counter\n",
    "raw_text_b += preexposure_b[0]\n",
    "labels_b += preexposure_b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04127b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcond_b = generate_language_from_labels(cleaned_postcond_b, 1)\n",
    "postcond_time_counter_b = time_counter\n",
    "raw_text_b += postcond_b[0]\n",
    "labels_b += postcond_b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e494ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC-C\n",
    "preexposure_c = generate_language_from_labels(cleaned_preexposure_c, 0)\n",
    "preexp_time_counter_c = time_counter\n",
    "raw_text_c += preexposure_c[0]\n",
    "labels_c += preexposure_c[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833cb0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcond_c = generate_language_from_labels(cleaned_postcond_c, 1)\n",
    "postcond_time_counter_c = time_counter\n",
    "raw_text_c += postcond_c[0]\n",
    "labels_c += postcond_c[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef900eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC-D (k)\n",
    "preexposure_k = generate_language_from_labels(cleaned_preexposure_k, 0)\n",
    "preexp_time_counter_k = time_counter\n",
    "raw_text_k += preexposure_k[0]\n",
    "labels_k += preexposure_k[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db7a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcond_k = generate_language_from_labels(cleaned_postcond_k, 1)\n",
    "postcond_time_counter_k = time_counter\n",
    "raw_text_k += postcond_k[0]\n",
    "labels_k += postcond_k[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab920440",
   "metadata": {},
   "outputs": [],
   "source": [
    "preexp_time_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcond_time_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc4c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_text), len(labels), len(raw_text) == len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c864d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a7024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing max sequence length\n",
    "max_seq_len = 0\n",
    "seq_lens = []\n",
    "overall_set = set()\n",
    "for seq in preexposure[0]:\n",
    "    overall_set.update(seq.split())\n",
    "    seq_lens.append(len(seq))\n",
    "    if len(seq) > max_seq_len:\n",
    "        max_seq_len = len(seq)\n",
    "print(\"Maximum sequence length:\", max_seq_len)\n",
    "seq_lens = np.array(seq_lens)\n",
    "print(\"Average:\", np.mean(seq_lens))\n",
    "print(\"Standard Deviation:\", np.std(seq_lens))\n",
    "print(\"Final Vocabulary:\", overall_set)\n",
    "print(\"Length of Vocabulary:\", len(overall_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef3eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time distributions:\n",
    "times = [time_counter[x] for x in time_counter.keys()]\n",
    "\n",
    "X = [x for x in time_counter.keys()]\n",
    "X_axis = np.arange(len(X))\n",
    "\n",
    "plt.figure(figsize=(30, 15))\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.bar(X_axis , times, 0.4, label = 'Preexposure')\n",
    "\n",
    "plt.xticks(X_axis, X)\n",
    "plt.xlabel(\"Time Buckets of Actions in seconds\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Action Frequency in Different Phases of Experiment Mouse\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae068de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_action_frequencies_d(action):\n",
    "    # Analyzing rests - Preexposure\n",
    "    preexp_rest_time_counter_k = {\n",
    "        'under5':0,\n",
    "        '5-10':0,\n",
    "        '10-15':0,\n",
    "        '15-20':0,\n",
    "        '20-25':0,\n",
    "        '25-30':0,\n",
    "        '30-35':0,\n",
    "        '35-40':0,\n",
    "        '40-45':0,\n",
    "        '45-50':0,\n",
    "        '50-55':0,\n",
    "        '55-60':0,\n",
    "        '60-90':0,\n",
    "        '90-450':0,\n",
    "        '450-1800':0,\n",
    "        '1800-4500':0,\n",
    "        'over4500':0,}\n",
    "\n",
    "    # Analyzing rests - Postconditioning\n",
    "    postcond_rest_time_counter_k = {\n",
    "        'under5':0,\n",
    "        '5-10':0,\n",
    "        '10-15':0,\n",
    "        '15-20':0,\n",
    "        '20-25':0,\n",
    "        '25-30':0,\n",
    "        '30-35':0,\n",
    "        '35-40':0,\n",
    "        '40-45':0,\n",
    "        '45-50':0,\n",
    "        '50-55':0,\n",
    "        '55-60':0,\n",
    "        '60-90':0,\n",
    "        '90-450':0,\n",
    "        '450-1800':0,\n",
    "        '1800-4500':0,\n",
    "        'over4500':0,}\n",
    "\n",
    "    for sentence in postcond_k[0]:\n",
    "        split_sentence = sentence.split()\n",
    "        for word_idx in range(len(split_sentence)):\n",
    "            if split_sentence[word_idx] == action:\n",
    "                preexp_rest_time_counter_k[split_sentence[word_idx+1]] += 1\n",
    "\n",
    "    for sentence in preexposure_k[0]:\n",
    "        split_sentence = sentence.split()\n",
    "        for word_idx in range(len(split_sentence)):\n",
    "            if split_sentence[word_idx] == action:\n",
    "                postcond_rest_time_counter_k[split_sentence[word_idx+1]] += 1\n",
    "\n",
    "    preexp_rest_times = [preexp_rest_time_counter_k[x] for x in preexp_rest_time_counter_k.keys()]\n",
    "    postcond_rest_times = [postcond_rest_time_counter_k[x] for x in postcond_rest_time_counter_k.keys()]\n",
    "\n",
    "    X = [x for x in preexp_rest_time_counter.keys()]\n",
    "    X_axis = np.arange(len(X))\n",
    "\n",
    "    plt.figure(figsize=(30, 15))\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    plt.bar(X_axis - 0.1, preexp_rest_times, 0.2, label = 'Preexposure')\n",
    "    plt.bar(X_axis + 0.1, postcond_rest_times, 0.2, label = 'Postcond')\n",
    "\n",
    "    plt.xticks(X_axis, X)\n",
    "    plt.xlabel(\"Time Buckets of \"+action+\" in seconds\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Action Frequency of \"+action+\" in Control Mouse\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce2807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_action_frequencies_c(action):\n",
    "    # Analyzing rests - Preexposure\n",
    "    preexp_rest_time_counter_c = {\n",
    "        'under5':0,\n",
    "        '5-10':0,\n",
    "        '10-15':0,\n",
    "        '15-20':0,\n",
    "        '20-25':0,\n",
    "        '25-30':0,\n",
    "        '30-35':0,\n",
    "        '35-40':0,\n",
    "        '40-45':0,\n",
    "        '45-50':0,\n",
    "        '50-55':0,\n",
    "        '55-60':0,\n",
    "        '60-90':0,\n",
    "        '90-450':0,\n",
    "        '450-1800':0,\n",
    "        '1800-4500':0,\n",
    "        'over4500':0,}\n",
    "\n",
    "    # Analyzing rests - Postconditioning\n",
    "    postcond_rest_time_counter_c = {\n",
    "        'under5':0,\n",
    "        '5-10':0,\n",
    "        '10-15':0,\n",
    "        '15-20':0,\n",
    "        '20-25':0,\n",
    "        '25-30':0,\n",
    "        '30-35':0,\n",
    "        '35-40':0,\n",
    "        '40-45':0,\n",
    "        '45-50':0,\n",
    "        '50-55':0,\n",
    "        '55-60':0,\n",
    "        '60-90':0,\n",
    "        '90-450':0,\n",
    "        '450-1800':0,\n",
    "        '1800-4500':0,\n",
    "        'over4500':0,}\n",
    "\n",
    "    for sentence in postcond_c[0]:\n",
    "        split_sentence = sentence.split()\n",
    "        for word_idx in range(len(split_sentence)):\n",
    "            if split_sentence[word_idx] == action:\n",
    "                preexp_rest_time_counter_c[split_sentence[word_idx+1]] += 1\n",
    "\n",
    "    for sentence in preexposure_c[0]:\n",
    "        split_sentence = sentence.split()\n",
    "        for word_idx in range(len(split_sentence)):\n",
    "            if split_sentence[word_idx] == action:\n",
    "                postcond_rest_time_counter_c[split_sentence[word_idx+1]] += 1\n",
    "\n",
    "    preexp_rest_times = [preexp_rest_time_counter_c[x] for x in preexp_rest_time_counter_c.keys()]\n",
    "    postcond_rest_times = [postcond_rest_time_counter_c[x] for x in postcond_rest_time_counter_c.keys()]\n",
    "\n",
    "    X = [x for x in preexp_rest_time_counter.keys()]\n",
    "    X_axis = np.arange(len(X))\n",
    "\n",
    "    plt.figure(figsize=(30, 15))\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    plt.bar(X_axis - 0.1, preexp_rest_times, 0.2, label = 'Preexposure')\n",
    "    plt.bar(X_axis + 0.1, postcond_rest_times, 0.2, label = 'Postcond')\n",
    "\n",
    "    plt.xticks(X_axis, X)\n",
    "    plt.xlabel(\"Time Buckets of \"+action+\" in seconds\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Action Frequency of \"+action+\" in Experiment Mouse\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2e16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_action_frequencies_b(action):\n",
    "    # Analyzing rests - Preexposure\n",
    "    preexp_rest_time_counter_b = {\n",
    "        'under5':0,\n",
    "        '5-10':0,\n",
    "        '10-15':0,\n",
    "        '15-20':0,\n",
    "        '20-25':0,\n",
    "        '25-30':0,\n",
    "        '30-35':0,\n",
    "        '35-40':0,\n",
    "        '40-45':0,\n",
    "        '45-50':0,\n",
    "        '50-55':0,\n",
    "        '55-60':0,\n",
    "        '60-90':0,\n",
    "        '90-450':0,\n",
    "        '450-1800':0,\n",
    "        '1800-4500':0,\n",
    "        'over4500':0,}\n",
    "\n",
    "    # Analyzing rests - Postconditioning\n",
    "    postcond_rest_time_counter_b = {\n",
    "        'under5':0,\n",
    "        '5-10':0,\n",
    "        '10-15':0,\n",
    "        '15-20':0,\n",
    "        '20-25':0,\n",
    "        '25-30':0,\n",
    "        '30-35':0,\n",
    "        '35-40':0,\n",
    "        '40-45':0,\n",
    "        '45-50':0,\n",
    "        '50-55':0,\n",
    "        '55-60':0,\n",
    "        '60-90':0,\n",
    "        '90-450':0,\n",
    "        '450-1800':0,\n",
    "        '1800-4500':0,\n",
    "        'over4500':0,}\n",
    "\n",
    "    for sentence in postcond_b[0]:\n",
    "        split_sentence = sentence.split()\n",
    "        for word_idx in range(len(split_sentence)):\n",
    "            if split_sentence[word_idx] == action:\n",
    "                preexp_rest_time_counter_b[split_sentence[word_idx+1]] += 1\n",
    "\n",
    "    for sentence in preexposure_b[0]:\n",
    "        split_sentence = sentence.split()\n",
    "        for word_idx in range(len(split_sentence)):\n",
    "            if split_sentence[word_idx] == action:\n",
    "                postcond_rest_time_counter_b[split_sentence[word_idx+1]] += 1\n",
    "\n",
    "    preexp_rest_times = [preexp_rest_time_counter_b[x] for x in preexp_rest_time_counter_b.keys()]\n",
    "    postcond_rest_times = [postcond_rest_time_counter_b[x] for x in postcond_rest_time_counter_b.keys()]\n",
    "\n",
    "    X = [x for x in preexp_rest_time_counter.keys()]\n",
    "    X_axis = np.arange(len(X))\n",
    "\n",
    "    plt.figure(figsize=(30, 15))\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    plt.bar(X_axis - 0.1, preexp_rest_times, 0.2, label = 'Preexposure')\n",
    "    plt.bar(X_axis + 0.1, postcond_rest_times, 0.2, label = 'Postcond')\n",
    "\n",
    "    plt.xticks(X_axis, X)\n",
    "    plt.xlabel(\"Time Buckets of \"+action+\" in seconds\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Action Frequency of \"+action+\" in Experiment Mouse\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719fc462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_action_frequencies(action):\n",
    "    # Analyzing rests - Preexposure\n",
    "    preexp_rest_time_counter = {\n",
    "        'under5':0,\n",
    "        '5-10':0,\n",
    "        '10-15':0,\n",
    "        '15-20':0,\n",
    "        '20-25':0,\n",
    "        '25-30':0,\n",
    "        '30-35':0,\n",
    "        '35-40':0,\n",
    "        '40-45':0,\n",
    "        '45-50':0,\n",
    "        '50-55':0,\n",
    "        '55-60':0,\n",
    "        '60-90':0,\n",
    "        '90-450':0,\n",
    "        '450-1800':0,\n",
    "        '1800-4500':0,\n",
    "        'over4500':0,}\n",
    "\n",
    "    # Analyzing rests - Postconditioning\n",
    "    postcond_rest_time_counter = {\n",
    "        'under5':0,\n",
    "        '5-10':0,\n",
    "        '10-15':0,\n",
    "        '15-20':0,\n",
    "        '20-25':0,\n",
    "        '25-30':0,\n",
    "        '30-35':0,\n",
    "        '35-40':0,\n",
    "        '40-45':0,\n",
    "        '45-50':0,\n",
    "        '50-55':0,\n",
    "        '55-60':0,\n",
    "        '60-90':0,\n",
    "        '90-450':0,\n",
    "        '450-1800':0,\n",
    "        '1800-4500':0,\n",
    "        'over4500':0,}\n",
    "\n",
    "    for sentence in postcond[0]:\n",
    "        split_sentence = sentence.split()\n",
    "        for word_idx in range(len(split_sentence)):\n",
    "            if split_sentence[word_idx] == action:\n",
    "                preexp_rest_time_counter[split_sentence[word_idx+1]] += 1\n",
    "\n",
    "    for sentence in preexposure[0]:\n",
    "        split_sentence = sentence.split()\n",
    "        for word_idx in range(len(split_sentence)):\n",
    "            if split_sentence[word_idx] == action:\n",
    "                postcond_rest_time_counter[split_sentence[word_idx+1]] += 1\n",
    "\n",
    "    preexp_rest_times = [preexp_rest_time_counter[x] for x in preexp_rest_time_counter.keys()]\n",
    "    postcond_rest_times = [postcond_rest_time_counter[x] for x in postcond_rest_time_counter.keys()]\n",
    "\n",
    "    X = [x for x in preexp_rest_time_counter.keys()]\n",
    "    X_axis = np.arange(len(X))\n",
    "\n",
    "    plt.figure(figsize=(30, 15))\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    plt.bar(X_axis - 0.1, preexp_rest_times, 0.2, label = 'Preexposure')\n",
    "    plt.bar(X_axis + 0.1, postcond_rest_times, 0.2, label = 'Postcond')\n",
    "\n",
    "    plt.xticks(X_axis, X)\n",
    "    plt.xlabel(\"Time Buckets of \"+action+\" in seconds\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Action Frequency of \"+action+\" in Experiment Mouse\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f82fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_action_frequencies_d(\"groom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b3a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_action_frequencies_c(\"rest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c228d4df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotting_action_frequencies_b(\"rest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb1d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_action_frequencies(\"rest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c330c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_action_frequencies_d(\"rear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_action_frequencies_c(\"rear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_action_frequencies_b(\"rear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_action_frequencies(\"rear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083351c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_action_frequencies_c(\"groom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01240280",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_action_frequencies(\"groom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d70780",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotting_action_frequencies(\"groom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd3081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_action_frequencies_d(\"nibble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d41318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_action_frequencies_c(\"nibble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80248a3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotting_action_frequencies(\"nibble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716811a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_action_frequencies_d(\"hang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b507a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()#vocab_size = 20, hidden_size = 24, num_hidden_layers = 6,  num_attention_heads = 12, intermediate_size = 1024, hidden_act = 'gelu', hidden_dropout_prob = 0.1, attention_probs_dropout_prob = 0.1,  max_position_embeddings = 45, type_vocab_size = 2, initializer_range = 0.02, layer_norm_eps = 1e-12, pad_token_id = 0, position_embedding_type = 'absolute',  use_cache = True, classifier_dropout = None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Vocabulary:\n",
    "# > '0-5'\n",
    "# > '5-15'\n",
    "# > '15-45'\n",
    "# > '45-90'\n",
    "# > '90-450'\n",
    "# > '450-1800'\n",
    "# > '1800-4500'\n",
    "# > 'over4500'\n",
    "# > 'drink'\n",
    "# > 'eat'\n",
    "# > 'groom'\n",
    "# > 'hang'\n",
    "# > 'sniff'\n",
    "# > 'rear'\n",
    "# > 'rest'\n",
    "# > 'walk'\n",
    "# > 'eathand'\n",
    "# > [CLS]\n",
    "# > [MASK]\n",
    "# > [SEP]\n",
    "\n",
    "# TOTAL SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ad2b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD]\r\n",
      "[UNK]\r\n",
      "[CLS]\r\n",
      "[SEP]\r\n",
      "[MASK]\r\n",
      "under5\r\n",
      "5-10\r\n",
      "10-15\r\n",
      "15-20\r\n",
      "20-25\r\n",
      "25-30\r\n",
      "30-35\r\n",
      "35-40\r\n",
      "40-45\r\n",
      "45-50\r\n",
      "50-55\r\n",
      "55-60\r\n",
      "60-90\r\n",
      "90-450\r\n",
      "450-1800\r\n",
      "1800-4500\r\n",
      "over4500\r\n",
      "drink\r\n",
      "eat\r\n",
      "groom\r\n",
      "hang\r\n",
      "sniff\r\n",
      "rear\r\n",
      "rest\r\n",
      "walk\r\n",
      "nibble"
     ]
    }
   ],
   "source": [
    "!cat nih_vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e1b15bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 2, 29,  5, 28,  6,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# repositor id for saving the tokenizer\n",
    "tokenizer_id=\"bert-base-uncased-2022-habana\"\n",
    "\n",
    "# create a python generator to dynamically load the data\n",
    "def batch_iterator(batch_size=100):\n",
    "    for i in tqdm(range(0, len(raw_text), batch_size)):\n",
    "        print(\"Batch:\", raw_text[i : i + batch_size])\n",
    "        yield raw_datasets[i : i + batch_size]\n",
    "\n",
    "# create a tokenizer from existing one to re-use special tokens\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer(\"nih_vocab.txt\", do_basic_tokenize=False)\n",
    "# tokenizer.add_tokens([\"0-5\", \"10-15\"])\n",
    "\n",
    "example_text = 'walk under5 rest 5-10'\n",
    "bert_input = tokenizer(example_text,padding='max_length', max_length = 512, \n",
    "                       truncation=True, return_tensors=\"pt\")\n",
    "print(bert_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d95ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = tokenizer.train_new_from_iterator(text_iterator=batch_iterator(), vocab_size = 20)\n",
    "# tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e66d2a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = np.load(\"all_30s_sequences.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c352fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════╤═════════════╕\n",
      "│ Tokens   │   Token IDs │\n",
      "╞══════════╪═════════════╡\n",
      "│ rest     │          28 │\n",
      "├──────────┼─────────────┤\n",
      "│ 5-10     │           6 │\n",
      "├──────────┼─────────────┤\n",
      "│ sniff    │          26 │\n",
      "├──────────┼─────────────┤\n",
      "│ 15-20    │           8 │\n",
      "├──────────┼─────────────┤\n",
      "│ walk     │          29 │\n",
      "├──────────┼─────────────┤\n",
      "│ 5-10     │           6 │\n",
      "├──────────┼─────────────┤\n",
      "│ sniff    │          26 │\n",
      "├──────────┼─────────────┤\n",
      "│ 90-450   │          18 │\n",
      "├──────────┼─────────────┤\n",
      "│ walk     │          29 │\n",
      "├──────────┼─────────────┤\n",
      "│ 5-10     │           6 │\n",
      "├──────────┼─────────────┤\n",
      "│ sniff    │          26 │\n",
      "├──────────┼─────────────┤\n",
      "│ 90-450   │          18 │\n",
      "├──────────┼─────────────┤\n",
      "│ walk     │          29 │\n",
      "├──────────┼─────────────┤\n",
      "│ 10-15    │           7 │\n",
      "├──────────┼─────────────┤\n",
      "│ sniff    │          26 │\n",
      "├──────────┼─────────────┤\n",
      "│ 90-450   │          18 │\n",
      "├──────────┼─────────────┤\n",
      "│ walk     │          29 │\n",
      "├──────────┼─────────────┤\n",
      "│ 10-15    │           7 │\n",
      "├──────────┼─────────────┤\n",
      "│ sniff    │          26 │\n",
      "├──────────┼─────────────┤\n",
      "│ 40-45    │          13 │\n",
      "├──────────┼─────────────┤\n",
      "│ rest     │          28 │\n",
      "├──────────┼─────────────┤\n",
      "│ 5-10     │           6 │\n",
      "├──────────┼─────────────┤\n",
      "│ sniff    │          26 │\n",
      "├──────────┼─────────────┤\n",
      "│ under5   │           5 │\n",
      "├──────────┼─────────────┤\n",
      "│ rest     │          28 │\n",
      "├──────────┼─────────────┤\n",
      "│ 5-10     │           6 │\n",
      "├──────────┼─────────────┤\n",
      "│ sniff    │          26 │\n",
      "├──────────┼─────────────┤\n",
      "│ 60-90    │          17 │\n",
      "├──────────┼─────────────┤\n",
      "│ rest     │          28 │\n",
      "├──────────┼─────────────┤\n",
      "│ under5   │           5 │\n",
      "├──────────┼─────────────┤\n",
      "│ sniff    │          26 │\n",
      "├──────────┼─────────────┤\n",
      "│ 90-450   │          18 │\n",
      "╘══════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "def print_rand_sentence():\n",
    "    '''\n",
    "    Displays the tokens and respective IDs of a random text sample\n",
    "    '''\n",
    "    index = random.randint(0, len(raw_text)-1)\n",
    "    table = np.array([tokenizer.tokenize(raw_text[index]), \n",
    "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(raw_text[index]))]).T\n",
    "    print(tabulate(table,\n",
    "                 headers = ['Tokens', 'Token IDs'],\n",
    "                 tablefmt = 'fancy_grid'))\n",
    "\n",
    "print_rand_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7fcdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sequences = raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0029d6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/gpfs/data/tserre/anagara8/pytorch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "token_id = []\n",
    "attention_masks = []\n",
    "\n",
    "def preprocessing(input_text, tokenizer):\n",
    "    return tokenizer.encode_plus(input_text, add_special_tokens = True, max_length = 512,\n",
    "                        pad_to_max_length = True, return_attention_mask = True, return_tensors = 'pt')\n",
    "\n",
    "for sequence in all_sequences:\n",
    "    encoding_dict = preprocessing(sequence, tokenizer)\n",
    "    token_id.append(encoding_dict['input_ids']) \n",
    "    attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "\n",
    "token_id = torch.cat(token_id, dim = 0)\n",
    "attention_masks = torch.cat(attention_masks, dim = 0)\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db0396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd1a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788fccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.2\n",
    "# Recommended batch size: 16, 32. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "batch_size = 16\n",
    "# Indices of the train and validation splits stratified by labels\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size = val_ratio,\n",
    "    shuffle = True,\n",
    "    stratify = labels)\n",
    "\n",
    "\n",
    "\n",
    "# Train and validation sets\n",
    "train_set = TensorDataset(token_id[train_idx], \n",
    "                          attention_masks[train_idx], \n",
    "                          labels[train_idx])\n",
    "\n",
    "val_set = TensorDataset(token_id[val_idx], \n",
    "                        attention_masks[val_idx], \n",
    "                        labels[val_idx])\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "            train_set,\n",
    "            sampler = RandomSampler(train_set),\n",
    "            batch_size = batch_size)\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_set,\n",
    "            sampler = SequentialSampler(val_set),\n",
    "            batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_tp(preds, labels):\n",
    "    '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
    "    return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fp(preds, labels):\n",
    "    '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
    "    return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_tn(preds, labels):\n",
    "    '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
    "    return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fn(preds, labels):\n",
    "    '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
    "    return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_metrics(preds, labels):\n",
    "    '''\n",
    "    Returns the following metrics:\n",
    "    - accuracy    = (TP + TN) / N\n",
    "    - precision   = TP / (TP + FP)\n",
    "    - recall      = TP / (TP + FN)\n",
    "    - specificity = TN / (TN + FP)\n",
    "    '''\n",
    "    preds = np.argmax(preds, axis = 1).flatten()\n",
    "    labels = labels.flatten()\n",
    "    tp = b_tp(preds, labels)\n",
    "    tn = b_tn(preds, labels)\n",
    "    fp = b_fp(preds, labels)\n",
    "    fn = b_fn(preds, labels)\n",
    "    b_accuracy = (tp + tn) / len(labels)\n",
    "    b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
    "    b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
    "    b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
    "    return b_accuracy, b_precision, b_recall, b_specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4dde0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BertForSequenceClassificationjkk model\n",
    "model = BertForSequenceClassification()#.from_pretrained(\n",
    "#     'bert-base-uncased',\n",
    "#     num_labels = 2,\n",
    "#     output_attentions = False,\n",
    "#     output_hidden_states = False,\n",
    "# )\n",
    "\n",
    "# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                              lr = 5e-5,\n",
    "                              eps = 1e-08\n",
    "                              )\n",
    "\n",
    "# Run on GPU\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7326ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Recommende number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "epochs = 20\n",
    "\n",
    "val_acc_overall = []\n",
    "train_loss_overall = []\n",
    "\n",
    "for _ in trange(epochs, desc = 'Epoch'):\n",
    "    \n",
    "    # ========== Training ==========\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Tracking variables\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        train_output = model(b_input_ids, \n",
    "                             token_type_ids = None, \n",
    "                             attention_mask = b_input_mask, \n",
    "                             labels = b_labels)\n",
    "        # Backward pass\n",
    "        train_output.loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update tracking variables\n",
    "        tr_loss += train_output.loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    # ========== Validation ==========\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    val_accuracy = []\n",
    "    val_precision = []\n",
    "    val_recall = []\n",
    "    val_specificity = []\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "          # Forward pass\n",
    "          eval_output = model(b_input_ids, \n",
    "                              token_type_ids = None, \n",
    "                              attention_mask = b_input_mask)\n",
    "        logits = eval_output.logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate validation metrics\n",
    "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
    "        val_accuracy.append(b_accuracy)\n",
    "        # Update precision only when (tp + fp) !=0; ignore nan\n",
    "        if b_precision != 'nan': val_precision.append(b_precision)\n",
    "        # Update recall only when (tp + fn) !=0; ignore nan\n",
    "        if b_recall != 'nan': val_recall.append(b_recall)\n",
    "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
    "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
    "\n",
    "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
    "    train_loss_overall.append(tr_loss)\n",
    "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
    "    val_acc_overall.append(val_accuracy)\n",
    "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
    "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
    "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aac2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preexposure_actions_17202338_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# category_names = ['Strongly disagree', 'Disagree',\n",
    "#                   'Neither agree nor disagree', 'Agree', 'Strongly agree']\n",
    "BEH_LABELS = ['drink', 'eat', 'groom', 'hang', 'sniff', 'rear', 'rest', 'walk', 'nibble']\n",
    "action_colours = ['tab:blue', 'tab:orange', 'limegreen', 'deepskyblue', 'tab:pink', 'tab:purple', 'tab:brown', 'red', 'black']\n",
    "results = {\n",
    "    'Question 1': [10, 15, 17, 32, 26],\n",
    "}\n",
    "\n",
    "\n",
    "def survey(results, category_names):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    results : dict\n",
    "        A mapping from question labels to a list of answers per category.\n",
    "        It is assumed all lists contain the same number of entries and that\n",
    "        it matches the length of *category_names*.\n",
    "    category_names : list of str\n",
    "        The category labels.\n",
    "    \"\"\"\n",
    "    labels = list(results.keys())\n",
    "    data = np.array(list(results.values()))\n",
    "    data_cum = data.cumsum(axis=1)\n",
    "    category_colors = plt.colormaps['RdYlGn'](\n",
    "        np.linspace(0.15, 0.85, data.shape[1]))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9.2, 1))\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.set_xlim(0, np.sum(data, axis=1).max())\n",
    "\n",
    "    for i, (colname, color) in enumerate(zip(BEH_LABELS, action_colours)):\n",
    "        widths = data[:, i]\n",
    "        starts = data_cum[:, i] - widths\n",
    "        rects = ax.barh(labels, widths, left=starts, height=0.5,\n",
    "                        label=colname, color=color)\n",
    "\n",
    "#         r, g, b, _ = color\n",
    "        text_color = color#'white' if r * g * b < 0.5 else 'darkgrey'\n",
    "        ax.bar_label(rects, label_type='center', color=text_color)\n",
    "    ax.legend(ncol=len(category_names), bbox_to_anchor=(0, 1),\n",
    "              loc='lower left', fontsize='small')\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "survey(results, category_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bcf189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([[0,1, 3, 5, 7]])\n",
    "pl.figure(figsize=(9, 1.5))\n",
    "img = pl.imshow(a, cmap=\"Blues\")\n",
    "pl.gca().set_visible(False)\n",
    "cax = pl.axes([0.1, 0.2, 0.8, 0.6])\n",
    "pl.colorbar(orientation=\"horizontal\", cax=cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5845fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.iloc[97720]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a48ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BEH_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b528eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ddf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b[0:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58023f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000\n",
    "plt.figure(figsize=(30, 1))\n",
    "barlist=plt.bar(range(1,n+1), [1*n])\n",
    "for i in range(n):\n",
    "    barlist[i].set_color(action_colours[c[i]])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14942efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
