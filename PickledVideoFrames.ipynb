{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anagara8/.conda/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models,transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import TensorDataset, DataLoader,random_split\n",
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.autograd import Function\n",
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import copy\n",
    "import torchvision.models as models\n",
    "import pickle\n",
    "import cv2\n",
    "import wandb\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "import decord\n",
    "from decord import VideoReader\n",
    "from decord import cpu, gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_DATASET = \"preexposure\"\n",
    "percentage_chance = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/media/data_cifs/nih/files_to_send/'\n",
    "datasets = os.listdir(base_path)\n",
    "\n",
    "postext_datasets = [dataset for dataset in datasets if 'postext' in dataset and \"Trap\" not in dataset ]\n",
    "postret_datasets = [dataset for dataset in datasets if 'postret' in dataset and \"Trap\" not in dataset ]\n",
    "postcond_datasets = [dataset for dataset in datasets if 'postcond' in dataset and \"Trap\" not in dataset ]\n",
    "preexposure_datasets = [dataset for dataset in datasets if 'preexposure' in dataset and \"Trap\" not in dataset ]\n",
    "\n",
    "if USE_DATASET == \"postext\":\n",
    "    dataset_to_use = postext_datasets\n",
    "elif USE_DATASET == \"postret\":\n",
    "    dataset_to_use = postret_datasets\n",
    "elif USE_DATASET == \"preexposure\":\n",
    "    dataset_to_use = preexposure_datasets\n",
    "else:\n",
    "    dataset_to_use = postcond_datasets\n",
    "\n",
    "all_datasets = [[('FC-A', 'preexposure', 'Trap'), ('FC-B','preexposure'), ('FC-C', 'preexposure'), ('FC-D', 'preexposure')],\n",
    "            [('FC-A', 'postcond', 'Trap'), ('FC-B','postcond'), ('FC-C', 'postcond'), ('FC-D', 'postcond')],\n",
    "            [('FC-A', 'postret', 'Trap'), ('FC-B','postret'), ('FC-C', 'postret'), ('FC-D', 'postret')],\n",
    "            [('FC-A', 'postext', 'Trap'), ('FC-B','postext'), ('FC-C', 'postext'), ('FC-D', 'postext')]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC-D_preexposure_W1_05-30-2019 : _d\n",
      "Number of files in Current Cohort (1 file = 1 hour of data): 144\n",
      "FC-D_preexposure_W1_05-30-2019video_2019Y_05M_30D_10h_47m_41s_cam_17202339-0000\n",
      "Completed FC-D_preexposure_W1_05-30-2019video_2019Y_05M_30D_10h_47m_41s_cam_17202339-0000 in 110 seconds.\n"
     ]
    }
   ],
   "source": [
    "for folder in dataset_to_use:\n",
    "    folder_path = base_path+folder\n",
    "#     print(\"FOLDER:\", folder)\n",
    "\n",
    "    append_character = folder.split('_')[0][-1]\n",
    "    append_character = \"_\"+append_character.lower()\n",
    "\n",
    "    print(folder, \":\", append_character)\n",
    "\n",
    "    # Working with postcond FC-A:\n",
    "    files = glob.glob(folder_path+\"/*.mp4\")\n",
    "    files.sort()\n",
    "    print(\"Number of files in Current Cohort (1 file = 1 hour of data):\", len(files))\n",
    "\n",
    "    # Sorting the file list to get data in order\n",
    "    files = sorted(files)\n",
    "\n",
    "    for file in files:     \n",
    "        file_save_name = file.rfind(\"/\", 0, file.rfind(\"/\"))\n",
    "        file_save_name = file[file_save_name:]\n",
    "        file_save_name = file_save_name.replace(\"/\", \"\")\n",
    "        file_save_name = file_save_name.replace(\".mp4\", \"\")\n",
    "        \n",
    "#         print(file_save_name)\n",
    "        tic = time.perf_counter()\n",
    "        \n",
    "        video_data = VideoReader(file, ctx=cpu())\n",
    "        decord.bridge.set_bridge('torch')\n",
    "        video_length = len(video_data)\n",
    "        \n",
    "        randomly_sampled_frames = [video_data[idx].numpy() for idx in np.random.randint(0, video_length, int(video_length*percentage_chance))] #random.choices(video_data, k=int(video_length*percentage_chance))\n",
    "        np.save(\"./\"+USE_DATASET+\"/\"+file_save_name, randomly_sampled_frames)\n",
    "        \n",
    "        toc = time.perf_counter()\n",
    "        print(\"Completed\", file_save_name, \"in\", int(toc - tic), \"seconds.\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythorch",
   "language": "python",
   "name": "pythorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
