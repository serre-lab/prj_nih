{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7547cb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anagara8/.conda/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models,transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import TensorDataset, DataLoader,random_split\n",
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.autograd import Function\n",
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torchvision.models as models\n",
    "import pickle\n",
    "import cv2\n",
    "import wandb\n",
    "from sklearn.model_selection import KFold\n",
    "# from torchsummary import summary\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed7f564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, scale_factor, mode='nearest'):\n",
    "        super().__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, scale_factor=self.scale_factor, mode=self.mode)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class BasicBlockEnc(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        planes = in_planes*stride\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        if stride == 1:\n",
    "            self.shortcut = nn.Sequential()\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    "\n",
    "class BasicBlockDec(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        planes = int(in_planes/stride)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(in_planes)\n",
    "        # self.bn1 could have been placed here, but that messes up the order of the layers when printing the class\n",
    "\n",
    "        if stride == 1:\n",
    "            self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(planes)\n",
    "            self.shortcut = nn.Sequential()\n",
    "        else:\n",
    "            self.conv1 = ResizeConv2d(in_planes, planes, kernel_size=3, scale_factor=stride)\n",
    "            self.bn1 = nn.BatchNorm2d(planes)\n",
    "            self.shortcut = nn.Sequential(\n",
    "                ResizeConv2d(in_planes, planes, kernel_size=3, scale_factor=stride),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn2(self.conv2(x)))\n",
    "        out = self.bn1(self.conv1(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet18Enc(nn.Module):\n",
    "    def __init__(self, z_dim=32):\n",
    "        super(ResNet18Enc, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.ResNet18 = models.resnet18(pretrained=True)\n",
    "        self.num_feature = self.ResNet18.fc.in_features\n",
    "        self.ResNet18.fc = nn.Linear(self.num_feature, 2*self.z_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.ResNet18(x)\n",
    "        mu = x[:, :self.z_dim]\n",
    "        logvar = x[:, self.z_dim:]\n",
    "        return mu, logvar\n",
    "    \n",
    "# class ResNet18Enc(nn.Module):\n",
    "\n",
    "#     def __init__(self, num_Blocks=[2,2,2,2], z_dim=128, nc=1):\n",
    "#         super(ResNet18Enc, self).__init__()\n",
    "#         self.in_planes = 64\n",
    "#         self.z_dim = z_dim\n",
    "#         self.conv1 = nn.Conv2d(nc, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(64)\n",
    "#         self.layer1 = self._make_layer(BasicBlockEnc, 64, num_Blocks[0], stride=1)\n",
    "#         self.layer2 = self._make_layer(BasicBlockEnc, 128, num_Blocks[1], stride=2)\n",
    "#         self.layer3 = self._make_layer(BasicBlockEnc, 256, num_Blocks[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(BasicBlockEnc, 512, num_Blocks[3], stride=2)\n",
    "# #         self.linear = nn.Linear(512, 2 * z_dim)\n",
    "#         self.linear = nn.Linear(512, z_dim)\n",
    "\n",
    "#     def _make_layer(self, BasicBlockEnc, planes, num_Blocks, stride):\n",
    "#         strides = [stride] + [1]*(num_Blocks-1)\n",
    "#         layers = []\n",
    "#         for stride in strides:\n",
    "#             layers += [BasicBlockEnc(self.in_planes, stride)]\n",
    "#             self.in_planes = planes\n",
    "#         return nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.bn1(self.conv1(x)))\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.layer2(x)\n",
    "#         x = self.layer3(x)\n",
    "#         x = self.layer4(x)\n",
    "#         x = F.adaptive_avg_pool2d(x, 1)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.linear(x)\n",
    "#         mu = x[:, :self.z_dim]\n",
    "#         logvar = x[:, self.z_dim:]\n",
    "# #         return mu, logvar\n",
    "#         return x\n",
    "\n",
    "class ResNet18Dec(nn.Module):\n",
    "\n",
    "    def __init__(self, num_Blocks=[2,2,2,2], z_dim=32, nc=3):\n",
    "        super().__init__()\n",
    "        self.in_planes = 512\n",
    "\n",
    "        self.linear = nn.Linear(z_dim, 512)\n",
    "\n",
    "        self.layer4 = self._make_layer(BasicBlockDec, 256, num_Blocks[3], stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlockDec, 128, num_Blocks[2], stride=2)\n",
    "        self.layer2 = self._make_layer(BasicBlockDec, 64, num_Blocks[1], stride=2)\n",
    "        self.layer1 = self._make_layer(BasicBlockDec, 64, num_Blocks[0], stride=1)\n",
    "        self.conv1 = ResizeConv2d(64, nc, kernel_size=3, scale_factor=2)\n",
    "\n",
    "    def _make_layer(self, BasicBlockDec, planes, num_Blocks, stride):\n",
    "        strides = [stride] + [1]*(num_Blocks-1)\n",
    "        layers = []\n",
    "        for stride in reversed(strides):\n",
    "            layers += [BasicBlockDec(self.in_planes, stride)]\n",
    "        self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.linear(z)\n",
    "        x = x.view(z.size(0), 512, 1, 1)\n",
    "        x = F.interpolate(x, scale_factor=7)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer1(x)\n",
    "        x = F.interpolate(x, size=(112,112), mode='bilinear')\n",
    "        x = torch.sigmoid(self.conv1(x))\n",
    "        # [x, channels, height, width]\n",
    "        x = x.view(x.size(0), 3, 224, 224)\n",
    "        return x\n",
    "\n",
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = ResNet18Enc(z_dim=z_dim)\n",
    "        self.decoder = ResNet18Dec(z_dim=z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        x = self.decoder(z)\n",
    "        return x, mean, logvar\n",
    "    \n",
    "    @staticmethod\n",
    "    def reparameterize(mean, logvar):\n",
    "        std = torch.exp(logvar / 2) # in log-space, squareroot is divide by two\n",
    "        epsilon = torch.randn_like(std)\n",
    "        return epsilon * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eaae98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_VAE(nn.Module):\n",
    "    def __init__(self, fc_hidden1=1024, fc_hidden2=768, drop_p=0.3, CNN_embed_dim=128):\n",
    "        super(ResNet_VAE, self).__init__()\n",
    "\n",
    "        self.fc_hidden1, self.fc_hidden2, self.CNN_embed_dim = fc_hidden1, fc_hidden2, CNN_embed_dim\n",
    "\n",
    "        # CNN architechtures\n",
    "        self.ch1, self.ch2, self.ch3, self.ch4 = 16, 32, 64, 128\n",
    "        self.k1, self.k2, self.k3, self.k4 = (5, 5), (3, 3), (3, 3), (3, 3)      # 2d kernal size\n",
    "        self.s1, self.s2, self.s3, self.s4 = (2, 2), (2, 2), (2, 2), (2, 2)      # 2d strides\n",
    "        self.pd1, self.pd2, self.pd3, self.pd4 = (0, 0), (0, 0), (0, 0), (0, 0)  # 2d padding\n",
    "\n",
    "        # encoding components\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        modules = list(resnet.children())[:-1]      # delete the last fc layer.\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.fc1 = nn.Linear(resnet.fc.in_features, self.fc_hidden1)\n",
    "        self.bn1 = nn.BatchNorm1d(self.fc_hidden1, momentum=0.01)\n",
    "        self.fc2 = nn.Linear(self.fc_hidden1, self.fc_hidden2)\n",
    "        self.bn2 = nn.BatchNorm1d(self.fc_hidden2, momentum=0.01)\n",
    "        # Latent vectors mu and sigma\n",
    "        self.fc3_mu = nn.Linear(self.fc_hidden2, self.CNN_embed_dim)      # output = CNN embedding latent variables\n",
    "        self.fc3_logvar = nn.Linear(self.fc_hidden2, self.CNN_embed_dim)  # output = CNN embedding latent variables\n",
    "\n",
    "        # Sampling vector\n",
    "        self.fc4 = nn.Linear(self.CNN_embed_dim, self.fc_hidden2)\n",
    "        self.fc_bn4 = nn.BatchNorm1d(self.fc_hidden2)\n",
    "        self.fc5 = nn.Linear(self.fc_hidden2, 64 * 4 * 4)\n",
    "        self.fc_bn5 = nn.BatchNorm1d(64 * 4 * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Decoder\n",
    "        self.convTrans6 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=self.k4, stride=self.s4,\n",
    "                               padding=self.pd4),\n",
    "            nn.BatchNorm2d(32, momentum=0.01),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.convTrans7 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=8, kernel_size=self.k3, stride=self.s3,\n",
    "                               padding=self.pd3),\n",
    "            nn.BatchNorm2d(8, momentum=0.01),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.convTrans8 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=8, out_channels=3, kernel_size=self.k2, stride=self.s2,\n",
    "                               padding=self.pd2),\n",
    "            nn.BatchNorm2d(3, momentum=0.01),\n",
    "            nn.Sigmoid()    # y = (y1, y2, y3) \\in [0 ,1]^3\n",
    "        )\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = self.resnet(x)  # ResNet\n",
    "        x = x.view(x.size(0), -1)  # flatten output of conv\n",
    "\n",
    "        # FC layers\n",
    "        x = self.bn1(self.fc1(x))\n",
    "        x = self.relu(x)\n",
    "        x = self.bn2(self.fc2(x))\n",
    "        x = self.relu(x)\n",
    "        # x = F.dropout(x, p=self.drop_p, training=self.training)\n",
    "        mu, logvar = self.fc3_mu(x), self.fc3_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = self.relu(self.fc_bn4(self.fc4(z)))\n",
    "        x = self.relu(self.fc_bn5(self.fc5(x))).view(-1, 64, 4, 4)\n",
    "        x = self.convTrans6(x)\n",
    "        x = self.convTrans7(x)\n",
    "        x = self.convTrans8(x)\n",
    "        x = F.interpolate(x, size=(224, 224), mode='bilinear')\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_reconst = self.decode(z)\n",
    "\n",
    "        return x_reconst, z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6be3ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_fc_hidden1, CNN_fc_hidden2 = 1024, 1024\n",
    "CNN_embed_dim = 128   # z-size\n",
    "res_size = 224        # ResNet image size\n",
    "dropout_p = 0.2\n",
    "vae = ResNet_VAE(fc_hidden1=CNN_fc_hidden1, fc_hidden2=CNN_fc_hidden2, drop_p=dropout_p, CNN_embed_dim=CNN_embed_dim)\n",
    "vae = nn.DataParallel(vae)\n",
    "vae = vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eb9ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_frames = np.load(\"/media/data_cifs/anagara8/8_video_frame_list.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56604f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'video_2018Y_08M_13D_12h_01m_44s_cam_17202341frame35950.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec725c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    pinMem = True # Flag for pinning GPU memory\n",
    "    print('GPU is available!')\n",
    "else:\n",
    "    pinMem = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3f73705",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/data_cifs/anagara8/video_processed_frames/'\n",
    "dimension = (224, 224)\n",
    "\n",
    "# training_data_list = [\"frame\"+str(frame_idx) for frame_idx in range(4,1000)]\n",
    "training_data_list = list_of_frames[:256]\n",
    "img_list = [cv2.imread(data_dir+training_data) for training_data in training_data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3309ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_list, augmentations = None):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.img_list = img_list\n",
    "        self.augmentations = augmentations\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_list[idx]\n",
    "        img = torch.tensor(self.img_list[idx]).float()\n",
    "        img = torch.permute(img, (2, 0, 1))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8502147f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 256 -> Training set size: 205 | Validation set size: 51\n"
     ]
    }
   ],
   "source": [
    "m=len(img_list)\n",
    "\n",
    "print(\"Length:\",m, \"-> Training set size:\", int(math.ceil(m-m*0.2)), \"| Validation set size:\", int(m*0.2))\n",
    "train_data, val_data = random_split(img_list, [int(math.ceil(m-m*0.2)), int(m*0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5758cf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to DataLoader\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "train_set_loader = torch.utils.data.DataLoader(MyDataset(train_data), batch_size=batch_size, num_workers = 4, shuffle=True)\n",
    "valid_set_loader = torch.utils.data.DataLoader(MyDataset(val_data), batch_size=batch_size, num_workers = 4, shuffle=True)\n",
    "# test_set_loader = torch.utils.data.DataLoader(MyDataset(test_dataset_list), batch_size=batch_size,shuffle=True, num_workers = 4)\n",
    "print(\"Converted to DataLoader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ce58ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_function(reconstructions, target, mean, logvar):\n",
    "#     mse_loss = nn.MSELoss()\n",
    "#     MSE = mse_loss(reconstructions, target)\n",
    "#     KLD = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "#     return MSE + KLD\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # MSE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    MSE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return MSE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2371673",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs =  30\n",
    "learningRate= 0.001\n",
    "\n",
    "autoencoder_optimizer = optim.Adam(vae.parameters(), lr = learningRate)\n",
    "scheduler = optim.lr_scheduler.StepLR(autoencoder_optimizer, step_size=30, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "954580e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"WANDB_API_KEY\"] = \"99528c40ebd16fca6632e963a943b99ac8a5f4b7\"\n",
    "\n",
    "# project = \"nih_animal_behavior\"\n",
    "# wandb.init(project=project, entity=\"serrelab\", id='Cropped_VAE')\n",
    "\n",
    "# wandb.config = {\n",
    "#   \"learning_rate\": learningRate,\n",
    "#   \"epochs\": number_of_epochs,\n",
    "#   \"batch_size\": batch_size\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "298e33bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Loss -> Training: 410527574.2500000 | Validation: -379775376.0000000\n",
      "[2] Loss -> Training: -377053703.2500000 | Validation: -23568757.3750000\n",
      "[3] Loss -> Training: -1262095920.0000000 | Validation: 663967168.0000000\n",
      "[4] Loss -> Training: -1825981304.0000000 | Validation: 1109420928.0000000\n",
      "[5] Loss -> Training: -2030837152.0000000 | Validation: 1356910688.0000000\n",
      "[6] Loss -> Training: -2180688096.0000000 | Validation: 1336562688.0000000\n",
      "[7] Loss -> Training: -2266351168.0000000 | Validation: 1091541568.0000000\n",
      "[8] Loss -> Training: -2329891904.0000000 | Validation: 847790624.0000000\n",
      "[9] Loss -> Training: -2397453856.0000000 | Validation: 636828576.0000000\n",
      "[10] Loss -> Training: -2444602528.0000000 | Validation: 461131520.0000000\n",
      "[11] Loss -> Training: -2487211312.0000000 | Validation: 296975112.0000000\n",
      "[12] Loss -> Training: -2523423072.0000000 | Validation: 117844432.0000000\n",
      "[13] Loss -> Training: -2561187888.0000000 | Validation: 16519144.0000000\n",
      "[14] Loss -> Training: -2601708112.0000000 | Validation: -83077148.0000000\n",
      "[15] Loss -> Training: -2641952736.0000000 | Validation: -156970176.0000000\n",
      "[16] Loss -> Training: -2669855824.0000000 | Validation: -197398056.0000000\n",
      "[17] Loss -> Training: -2702596720.0000000 | Validation: -248696072.0000000\n",
      "[18] Loss -> Training: -2736112224.0000000 | Validation: -308120368.0000000\n",
      "[19] Loss -> Training: -2775475440.0000000 | Validation: -330436168.0000000\n",
      "[20] Loss -> Training: -2818355616.0000000 | Validation: -366822208.0000000\n",
      "[21] Loss -> Training: -2847709584.0000000 | Validation: -377079440.0000000\n",
      "[22] Loss -> Training: -2879812640.0000000 | Validation: -409530112.0000000\n",
      "[23] Loss -> Training: -2906391168.0000000 | Validation: -456422976.0000000\n",
      "[24] Loss -> Training: -2941518256.0000000 | Validation: -483558048.0000000\n",
      "[25] Loss -> Training: -2968101952.0000000 | Validation: -537472160.0000000\n",
      "[26] Loss -> Training: -2999050048.0000000 | Validation: -587512880.0000000\n",
      "[27] Loss -> Training: -3035380560.0000000 | Validation: -597320352.0000000\n",
      "[28] Loss -> Training: -3061197328.0000000 | Validation: -621556240.0000000\n",
      "[29] Loss -> Training: -3091559216.0000000 | Validation: -629228400.0000000\n",
      "[30] Loss -> Training: -3119068016.0000000 | Validation: -616216592.0000000\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_train_loss = []\n",
    "list_val_loss = []\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "    train_run_loss = 0 \n",
    "    val_run_loss = 0\n",
    "    vae.train(True) # For training\n",
    "    for image_batch in train_set_loader:\n",
    "        image_batch = image_batch.cuda()\n",
    "        autoencoder_optimizer.zero_grad()\n",
    "        enc_dec_img, z, mean, logvar = vae(image_batch)\n",
    "        train_loss = loss_function(enc_dec_img, image_batch, mean, logvar)\n",
    "        # Backward pass\n",
    "        train_loss.backward()\n",
    "        autoencoder_optimizer.step()\n",
    "        train_run_loss += train_loss.data.item()\n",
    "\n",
    "    vae.eval()\n",
    "    for image_batch in valid_set_loader:\n",
    "        image_batch = image_batch.cuda()\n",
    "        autoencoder_optimizer.zero_grad()\n",
    "        enc_dec_img, z, mean, logvar = vae(image_batch)\n",
    "        val_loss = loss_function(enc_dec_img, image_batch, mean, logvar)\n",
    "\n",
    "        val_run_loss += val_loss.data.item()\n",
    "        \n",
    "    print('[%d] Loss -> Training: %.7f | Validation: %.7f' % (epoch + 1, train_run_loss/2, val_run_loss/2))\n",
    "    list_val_loss.append(val_run_loss/5000)\n",
    "    list_train_loss.append(train_run_loss/5000)\n",
    "\n",
    "    plt.plot(range(epoch+1),list_train_loss,'tab:orange',label='Training Loss')\n",
    "    plt.plot(range(epoch+1),list_val_loss,'tab:blue',label='Validation Loss')\n",
    "    \n",
    "#     wandb.log({\"train_loss\": train_run_loss/5000, \"val_loss\": val_run_loss/5000})\n",
    "#     wandb.watch(vae)\n",
    "\n",
    "    if epoch%1 == 0:\n",
    "        # Log image(s)\n",
    "#         plt.imshow(image_batch.squeeze().permute(0, 2, 3, 1).cpu(), cmap='gist_gray')\n",
    "#         plt.imshow(enc_dec_img.squeeze().detach().cpu(), cmap='gist_gray')        \n",
    "#         wandb.log({\"reconstructed\": [wandb.Image(enc_dec_img.squeeze().cpu(), caption=\"Reconstructed Image\")]})\n",
    "#         wandb.log({\"target\": [wandb.Image(image_batch.squeeze().cpu(), caption=\"Target Image\")]})\n",
    "        torch.save(vae.state_dict(), \"croppedVAE_e\"+str(epoch)+\"_vL\"+str(val_run_loss)+\".p\")\n",
    "    if epoch==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        \n",
    "    val_run_loss = 0.0\n",
    "    train_run_loss = 0.0\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78d23101",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_reconstruction = enc_dec_img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2b0443e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 224, 224) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_reconstruction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[1;32m    454\u001b[0m     warn_deprecated(\n\u001b[1;32m    455\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    458\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/matplotlib/pyplot.py:2652\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2646\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[1;32m   2647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[1;32m   2648\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2649\u001b[0m         alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   2650\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, filternorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, filterrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4.0\u001b[39m,\n\u001b[1;32m   2651\u001b[0m         resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2652\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2654\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2656\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2659\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2660\u001b[0m     sci(__ret)\n\u001b[1;32m   2661\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[1;32m    454\u001b[0m     warn_deprecated(\n\u001b[1;32m    455\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    458\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/matplotlib/__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1414\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1415\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1416\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/matplotlib/axes/_axes.py:5481\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5474\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m   5475\u001b[0m im \u001b[38;5;241m=\u001b[39m mimage\u001b[38;5;241m.\u001b[39mAxesImage(\u001b[38;5;28mself\u001b[39m, cmap, norm, interpolation,\n\u001b[1;32m   5476\u001b[0m                       origin, extent, filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[1;32m   5477\u001b[0m                       filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[1;32m   5478\u001b[0m                       interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[1;32m   5479\u001b[0m                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5481\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5482\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5484\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/matplotlib/image.py:715\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A[:, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    714\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    716\u001b[0m                     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 224, 224) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample_reconstruction.detach().cpu().transpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47bcdf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythorch",
   "language": "python",
   "name": "pythorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
